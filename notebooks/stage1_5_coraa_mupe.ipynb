{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1.5 ‚Äî Latent Separability Audit\n",
    "\n",
    "**Projeto:** Controle Expl√≠cito de Sotaque Regional em pt-BR  \n",
    "**Objetivo:** Verificar se representa√ß√µes internas do Qwen3-TTS codificam informa√ß√£o suficiente de sotaque regional para classifica√ß√£o acima de chance, com leakage controlado.  \n",
    "**Backbone:** Qwen3-TTS 1.7B-CustomVoice (frozen)  \n",
    "**Dataset:** CORAA-MUPE (speaker-disjoint splits)  \n",
    "\n",
    "Este notebook √© a **camada de orquestra√ß√£o**. Toda l√≥gica est√° em `src/` (test√°vel, audit√°vel).  \n",
    "O notebook apenas: instala deps ‚Üí configura ambiente ‚Üí chama m√≥dulos ‚Üí exibe resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.10.0 Requires-Python <3.12,>=3.8; 1.10.0rc1 Requires-Python <3.12,>=3.8; 1.10.0rc2 Requires-Python <3.12,>=3.8; 1.10.1 Requires-Python <3.12,>=3.8; 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11; 1.9.0 Requires-Python >=3.8,<3.12; 1.9.0rc1 Requires-Python >=3.8,<3.12; 1.9.0rc2 Requires-Python >=3.8,<3.12; 1.9.0rc3 Requires-Python >=3.8,<3.12; 1.9.1 Requires-Python >=3.8,<3.12\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement qwen-tts==1.0.1 (from versions: 0.0.2, 0.0.3, 0.0.4, 0.0.5, 0.1.0, 0.1.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for qwen-tts==1.0.1\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "Environment OK (numpy==2.0.2)\n"
     ]
    }
   ],
   "source": [
    "import os, subprocess, sys\n",
    "\n",
    "REPO_DIR = '/content/TCC'\n",
    "\n",
    "# 1. Clone repo (idempotent ‚Äî skips if already cloned)\n",
    "if not os.path.exists(os.path.join(REPO_DIR, '.git')):\n",
    "    !rm -rf {REPO_DIR}\n",
    "    !git clone https://github.com/paulohenriquevn/tcc.git {REPO_DIR}\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "!pip install -r requirements.txt -q\n",
    "\n",
    "# 2. NumPy ABI check ‚Äî Colab pre-loads numpy 2.x in memory, but\n",
    "#    requirements.txt pins 1.26.4. After pip downgrades the on-disk\n",
    "#    files, stale C-extensions cause:\n",
    "#      \"numpy.dtype size changed, may indicate binary incompatibility\"\n",
    "#    Fix: restart runtime ONCE. After restart both match ‚Üí no loop.\n",
    "_installed_np = subprocess.check_output(\n",
    "    [sys.executable, '-c', 'import numpy; print(numpy.__version__)'],\n",
    "    text=True,\n",
    ").strip()\n",
    "\n",
    "try:\n",
    "    import numpy as _np\n",
    "    _loaded_np = _np.__version__\n",
    "except Exception:\n",
    "    _loaded_np = None\n",
    "\n",
    "if _loaded_np != _installed_np:\n",
    "    print(f'\\nNumPy ABI mismatch: loaded={_loaded_np}, installed={_installed_np}')\n",
    "    print('Restarting runtime... After restart, re-run this cell (no second restart).')\n",
    "    os.kill(os.getpid(), 9)\n",
    "else:\n",
    "    print(f'\\nEnvironment OK (numpy=={_installed_np})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeds e determinismo ‚Äî OBRIGAT√ìRIO antes de qualquer opera√ß√£o\n",
    "from src.utils.seed import set_global_seed\n",
    "\n",
    "SEED = 42\n",
    "generator = set_global_seed(SEED)\n",
    "print(f'Seed global configurado: {SEED}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar GPU e vers√µes\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'CUDA device: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'CUDA version: {torch.version.cuda}')\n",
    "    print(f'VRAM total: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB')\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'\\nUsando device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar config\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "CONFIG_PATH = Path('configs/stage1_5.yaml')\n",
    "with open(CONFIG_PATH) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Experiment: {config['experiment']['name']}\")\n",
    "print(f\"Seed: {config['seed']['global']}\")\n",
    "print(f\"Dataset: {config['dataset']['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download e Build Manifest\n",
    "\n",
    "Baixa o CORAA-MUPE-ASR do HuggingFace, aplica filtros e constr√≥i o manifest JSONL.  \n",
    "\n",
    "**Filtros aplicados:**  \n",
    "- `speaker_type='R'` (apenas entrevistados, n√£o entrevistadores)  \n",
    "- Dura√ß√£o: 3‚Äì15s  \n",
    "- `birth_state` v√°lido ‚Üí macro-regi√£o IBGE (N, NE, CO, SE, S)  \n",
    "- G√™nero: M ou F  \n",
    "\n",
    "**Nota:** O download inicial √© ~42 GB. Runs subsequentes usam o cache do HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "print('Downloading CORAA-MUPE-ASR from HuggingFace...')\n",
    "print('(~42 GB na primeira vez ‚Äî usa cache nas pr√≥ximas execu√ß√µes)\\n')\n",
    "\n",
    "ds = load_dataset(\"nilc-nlp/CORAA-MUPE-ASR\")\n",
    "\n",
    "print(f'Splits dispon√≠veis: {list(ds.keys())}')\n",
    "for split_name, split_data in ds.items():\n",
    "    print(f'  {split_name}: {len(split_data):,} rows')\n",
    "\n",
    "# Concatenar todos os splits ‚Äî criaremos nossos pr√≥prios splits speaker-disjoint\n",
    "all_data = concatenate_datasets([ds[split] for split in ds.keys()])\n",
    "print(f'\\nTotal concatenado: {len(all_data):,} rows')\n",
    "print(f'Colunas: {all_data.column_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.manifest_builder import build_manifest_from_hf_dataset\n",
    "\n",
    "AUDIO_DIR = Path('data/audio/')\n",
    "MANIFEST_PATH = Path(config['dataset']['manifest_path'])\n",
    "\n",
    "entries, build_stats = build_manifest_from_hf_dataset(\n",
    "    dataset=all_data,\n",
    "    audio_output_dir=AUDIO_DIR,\n",
    "    manifest_output_path=MANIFEST_PATH,\n",
    "    speaker_type_filter=config['dataset']['filters']['speaker_type'],\n",
    "    min_duration_s=config['dataset']['filters']['min_duration_s'],\n",
    "    max_duration_s=config['dataset']['filters']['max_duration_s'],\n",
    "    min_speakers_per_region=config['dataset']['filters']['min_speakers_per_region'],\n",
    ")\n",
    "\n",
    "print(f\"\\nManifest: {len(entries):,} entries\")\n",
    "print(f\"SHA-256: {build_stats['manifest_sha256']}\")\n",
    "print(f\"\\nFilter stats:\")\n",
    "for key, count in build_stats['filter_stats'].items():\n",
    "    print(f\"  {key}: {count:,}\")\n",
    "print(f\"\\nRegi√µes:\")\n",
    "for region, info in build_stats['regions'].items():\n",
    "    print(f\"  {region}: {info['n_speakers']} speakers, {info['n_utterances']:,} utterances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Speaker-Disjoint Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.splits import (\n",
    "    generate_speaker_disjoint_splits,\n",
    "    generate_stratified_splits,\n",
    "    save_splits,\n",
    "    save_stratified_splits,\n",
    "    assign_entries_to_splits,\n",
    "    assign_entries_to_stratified_splits,\n",
    ")\n",
    "\n",
    "split_info = generate_speaker_disjoint_splits(\n",
    "    entries,\n",
    "    train_ratio=config['splits']['ratios']['train'],\n",
    "    val_ratio=config['splits']['ratios']['val'],\n",
    "    test_ratio=config['splits']['ratios']['test'],\n",
    "    seed=config['splits']['seed'],\n",
    ")\n",
    "\n",
    "# Persistir splits\n",
    "split_path = save_splits(split_info, Path(config['splits']['output_dir']))\n",
    "print(f\"Splits salvos em: {split_path}\")\n",
    "print(f\"Train: {len(split_info.train_speakers)} speakers, {split_info.utterances_per_split['train']} utts\")\n",
    "print(f\"Val:   {len(split_info.val_speakers)} speakers, {split_info.utterances_per_split['val']} utts\")\n",
    "print(f\"Test:  {len(split_info.test_speakers)} speakers, {split_info.utterances_per_split['test']} utts\")\n",
    "\n",
    "# Assign entries (speaker-disjoint)\n",
    "split_entries = assign_entries_to_splits(entries, split_info)\n",
    "\n",
    "# Generate stratified split for leakage A‚Üíspeaker probes\n",
    "stratified_split_info = generate_stratified_splits(\n",
    "    entries,\n",
    "    train_ratio=config['splits']['ratios']['train'],\n",
    "    seed=config['splits']['seed'],\n",
    ")\n",
    "stratified_split_path = save_stratified_splits(\n",
    "    stratified_split_info, Path(config['splits']['output_dir'])\n",
    ")\n",
    "stratified_entries = assign_entries_to_stratified_splits(entries, stratified_split_info)\n",
    "print(f\"\\nStratified splits salvos em: {stratified_split_path}\")\n",
    "print(f\"Stratified Train: {stratified_split_info.utterances_per_split['train']} utts\")\n",
    "print(f\"Stratified Test:  {stratified_split_info.utterances_per_split['test']} utts\")\n",
    "print(f\"Speakers in common: {stratified_split_info.speakers_in_common}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An√°lise de Confounds\n",
    "\n",
    "**Sanity checks obrigat√≥rios** (recomenda√ß√£o do mentor):  \n",
    "- Tabela accent √ó gender com chi-quadrado + Cramer's V  \n",
    "- Histograma de dura√ß√£o por regi√£o + Kruskal-Wallis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.confounds import run_all_confound_checks\n",
    "import pandas as pd\n",
    "\n",
    "confound_results = run_all_confound_checks(\n",
    "    entries,\n",
    "    gender_blocking_threshold=config['evaluation']['confounds']['accent_x_gender']['threshold_blocker'],\n",
    "    duration_practical_diff_s=config['evaluation']['confounds']['accent_x_duration']['practical_diff_s'],\n",
    "    snr_practical_diff_db=config['evaluation']['confounds']['accent_x_snr']['practical_diff_db'],\n",
    ")\n",
    "\n",
    "print(\"=== CONFOUND ANALYSIS ===\")\n",
    "for result in confound_results:\n",
    "    status = 'üî¥ BLOCKING' if result.is_blocking else ('üü° SIGNIFICANT' if result.is_significant else 'üü¢ OK')\n",
    "    print(f\"\\n{result.variable_a} √ó {result.variable_b}: {status}\")\n",
    "    print(f\"  Test: {result.test_name}\")\n",
    "    print(f\"  Statistic: {result.statistic:.4f}\")\n",
    "    print(f\"  p-value: {result.p_value:.6f}\")\n",
    "    print(f\"  Effect size ({result.effect_size_name}): {result.effect_size:.4f}\")\n",
    "    print(f\"  Interpretation: {result.interpretation}\")\n",
    "\n",
    "# Tabela accent x gender\n",
    "gender_table = pd.crosstab(\n",
    "    [e.accent for e in entries],\n",
    "    [e.gender for e in entries],\n",
    "    margins=True,\n",
    ")\n",
    "print(\"\\n=== ACCENT √ó GENDER TABLE ===\")\n",
    "print(gender_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de dura√ß√£o por regi√£o\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "durations_df = pd.DataFrame([\n",
    "    {'accent': e.accent, 'duration_s': e.duration_s}\n",
    "    for e in entries\n",
    "])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.boxplot(data=durations_df, x='accent', y='duration_s', ax=ax,\n",
    "            order=sorted(durations_df['accent'].unique()))\n",
    "ax.set_title('Duration by Accent Region')\n",
    "ax.set_xlabel('Macro-Region (IBGE)')\n",
    "ax.set_ylabel('Duration (s)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('reports/figures/duration_by_accent.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction\n",
    "\n",
    "Extrai features de 4 fontes:\n",
    "1. **Ac√∫sticas** (MFCC, pitch, energy, speech rate) ‚Äî CPU\n",
    "2. **ECAPA-TDNN** (speaker embeddings, 192-dim) ‚Äî CPU/GPU\n",
    "3. **WavLM** (SSL features, 5 camadas) ‚Äî GPU recomendado\n",
    "4. **Qwen3-TTS** (backbone features, 8 camadas) ‚Äî GPU obrigat√≥rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from src.features.acoustic import extract_acoustic_features, features_to_vector\n",
    "from src.features.ecapa import extract_ecapa_embedding\n",
    "\n",
    "# 4.1 Acoustic features (CPU, fast)\n",
    "print('=== Extracting acoustic features ===')\n",
    "acoustic_vectors = {}\n",
    "for entry in tqdm(entries, desc='Acoustic'):\n",
    "    feats = extract_acoustic_features(\n",
    "        Path(entry.audio_path), entry.utt_id,\n",
    "        n_mfcc=config['features']['acoustic']['n_mfcc'],\n",
    "    )\n",
    "    acoustic_vectors[entry.utt_id] = features_to_vector(feats)\n",
    "\n",
    "print(f'Extracted {len(acoustic_vectors)} acoustic feature vectors')\n",
    "print(f'Dimension: {next(iter(acoustic_vectors.values())).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 ECAPA-TDNN speaker embeddings\n",
    "print('=== Extracting ECAPA embeddings ===')\n",
    "ecapa_embeddings = {}\n",
    "for entry in tqdm(entries, desc='ECAPA'):\n",
    "    emb = extract_ecapa_embedding(Path(entry.audio_path), device=DEVICE)\n",
    "    ecapa_embeddings[entry.utt_id] = emb\n",
    "\n",
    "print(f'Extracted {len(ecapa_embeddings)} ECAPA embeddings')\n",
    "print(f'Dimension: {next(iter(ecapa_embeddings.values())).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 WavLM SSL features (layer-wise)\n",
    "from src.features.ssl import extract_ssl_features\n",
    "\n",
    "SSL_LAYERS = config['features']['ssl']['layers']\n",
    "print(f'=== Extracting WavLM features (layers {SSL_LAYERS}) ===')\n",
    "\n",
    "ssl_features = {layer: {} for layer in SSL_LAYERS}  # {layer: {utt_id: vector}}\n",
    "for entry in tqdm(entries, desc='WavLM'):\n",
    "    layer_feats = extract_ssl_features(\n",
    "        Path(entry.audio_path),\n",
    "        layers=SSL_LAYERS,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    for layer_idx, feat_vec in layer_feats.items():\n",
    "        ssl_features[layer_idx][entry.utt_id] = feat_vec\n",
    "\n",
    "print(f'WavLM extraction complete')\n",
    "for layer in SSL_LAYERS:\n",
    "    dim = next(iter(ssl_features[layer].values())).shape\n",
    "    print(f'  Layer {layer}: {len(ssl_features[layer])} vectors, dim={dim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Qwen3-TTS backbone features (layer-wise) ‚Äî GPU required\n",
    "from src.features.backbone import extract_backbone_features\n",
    "\n",
    "BACKBONE_LAYERS = config['features']['backbone']['layers']\n",
    "print(f'=== Extracting backbone features (layers {BACKBONE_LAYERS}) ===')\n",
    "\n",
    "backbone_features = {layer: {} for layer in BACKBONE_LAYERS}\n",
    "# Note: backbone needs text input. Use a fixed neutral text for all utterances\n",
    "# since we're probing the audio representation, not text-conditioned generation.\n",
    "NEUTRAL_TEXT = 'Este √© um texto neutro para extra√ß√£o de features.'\n",
    "\n",
    "for entry in tqdm(entries, desc='Backbone'):\n",
    "    layer_feats = extract_backbone_features(\n",
    "        Path(entry.audio_path),\n",
    "        text=NEUTRAL_TEXT,\n",
    "        layers=BACKBONE_LAYERS,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    for layer_idx, feat_vec in layer_feats.items():\n",
    "        backbone_features[layer_idx][entry.utt_id] = feat_vec\n",
    "\n",
    "print(f'Backbone extraction complete')\n",
    "for layer in BACKBONE_LAYERS:\n",
    "    if backbone_features[layer]:\n",
    "        dim = next(iter(backbone_features[layer].values())).shape\n",
    "        print(f'  Layer {layer}: {len(backbone_features[layer])} vectors, dim={dim}')\n",
    "\n",
    "# Free GPU memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Baseline ECAPA Speaker Similarity\n",
    "\n",
    "Mede similaridade intra-speaker (mesmo speaker, utterances diferentes) e inter-speaker no √°udio real.  \n",
    "Este baseline √© refer√™ncia obrigat√≥ria para Stage 2 (preserva√ß√£o de identidade com LoRA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.ecapa import compute_speaker_similarity_baseline\n",
    "from src.evaluation.bootstrap_ci import bootstrap_cosine_similarity\n",
    "\n",
    "# Group embeddings by speaker\n",
    "speaker_embs = {}\n",
    "for entry in entries:\n",
    "    speaker_embs.setdefault(entry.speaker_id, []).append(\n",
    "        ecapa_embeddings[entry.utt_id]\n",
    "    )\n",
    "\n",
    "sim_baseline = compute_speaker_similarity_baseline(speaker_embs)\n",
    "\n",
    "# CI for intra and inter\n",
    "intra_ci = bootstrap_cosine_similarity(\n",
    "    np.array(sim_baseline['intra']['values']), seed=SEED\n",
    ")\n",
    "inter_ci = bootstrap_cosine_similarity(\n",
    "    np.array(sim_baseline['inter']['values']), seed=SEED\n",
    ")\n",
    "\n",
    "print('=== SPEAKER SIMILARITY BASELINE (ECAPA-TDNN, 192-dim) ===')\n",
    "print(f\"Intra-speaker: {sim_baseline['intra']['mean']:.4f} ¬± {sim_baseline['intra']['std']:.4f}\")\n",
    "print(f\"  CI 95%: [{intra_ci.ci_lower:.4f}, {intra_ci.ci_upper:.4f}]\")\n",
    "print(f\"  N pairs: {sim_baseline['intra']['n_pairs']}\")\n",
    "print(f\"\\nInter-speaker: {sim_baseline['inter']['mean']:.4f} ¬± {sim_baseline['inter']['std']:.4f}\")\n",
    "print(f\"  CI 95%: [{inter_ci.ci_lower:.4f}, {inter_ci.ci_upper:.4f}]\")\n",
    "print(f\"  N pairs: {sim_baseline['inter']['n_pairs']}\")\n",
    "print(f\"\\nSeparation: {sim_baseline['intra']['mean'] - sim_baseline['inter']['mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Linear Probes\n",
    "\n",
    "Probe architecture: **Logistic Regression** (linear only ‚Äî protocol requirement).  \n",
    "\n",
    "Split assignments (corrected ‚Äî Achado 1 da auditoria):  \n",
    "- Accent probe: **speaker-disjoint** split  \n",
    "- Speaker probe: **stratified** split  \n",
    "- Leakage A‚Üíspeaker: **stratified** split (same speakers in train/test)  \n",
    "- Leakage S‚Üíaccent: **speaker-disjoint** split (different speakers in test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation.probes import (\n",
    "    train_linear_probe,\n",
    "    evaluate_probe_against_thresholds,\n",
    "    sweep_regularization,\n",
    "    train_selectivity_control,\n",
    ")\n",
    "from src.evaluation.confusion import plot_confusion_matrix\n",
    "\n",
    "# Helper: build X, y arrays from features dict and entries\n",
    "def build_probe_data(feature_dict, entry_list, target_field):\n",
    "    \"\"\"Build X, y arrays for probing.\"\"\"\n",
    "    X, y = [], []\n",
    "    for entry in entry_list:\n",
    "        if entry.utt_id in feature_dict:\n",
    "            X.append(feature_dict[entry.utt_id])\n",
    "            y.append(getattr(entry, target_field))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Collect all probe results\n",
    "all_probe_results = []\n",
    "all_selectivity_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Accent Probe (per layer, speaker-disjoint split)\n",
    "print('=== ACCENT PROBES ===')\n",
    "\n",
    "# Build train/test for speaker-disjoint\n",
    "train_entries = split_entries['train']\n",
    "test_entries = split_entries['test']\n",
    "\n",
    "# Probe each feature source\n",
    "feature_sources = {}\n",
    "\n",
    "# Acoustic\n",
    "feature_sources['acoustic'] = acoustic_vectors\n",
    "\n",
    "# ECAPA\n",
    "feature_sources['ecapa'] = ecapa_embeddings\n",
    "\n",
    "# WavLM layers\n",
    "for layer in SSL_LAYERS:\n",
    "    feature_sources[f'wavlm_layer_{layer}'] = ssl_features[layer]\n",
    "\n",
    "# Backbone layers\n",
    "for layer in BACKBONE_LAYERS:\n",
    "    if backbone_features[layer]:\n",
    "        feature_sources[f'backbone_layer_{layer}'] = backbone_features[layer]\n",
    "\n",
    "C_values = config['probes']['regularization_C']\n",
    "\n",
    "for source_name, feat_dict in feature_sources.items():\n",
    "    X_train, y_train = build_probe_data(feat_dict, train_entries, 'accent')\n",
    "    X_test, y_test = build_probe_data(feat_dict, test_entries, 'accent')\n",
    "    \n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(f'  {source_name}: SKIPPED (no data)')\n",
    "        continue\n",
    "    \n",
    "    # Sweep regularization to find best C\n",
    "    sweep_results = sweep_regularization(\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        C_values=C_values,\n",
    "        probe_name=f'accent_{source_name}',\n",
    "        feature_source=source_name,\n",
    "        target='accent',\n",
    "        split_type='speaker_disjoint',\n",
    "        seed=SEED,\n",
    "    )\n",
    "    best_sweep = max(sweep_results, key=lambda r: r.balanced_accuracy)\n",
    "    best_C = best_sweep.regularization_C\n",
    "    \n",
    "    # Re-train with best C and full CI\n",
    "    result = train_linear_probe(\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        probe_name=f'accent_{source_name}',\n",
    "        feature_source=source_name,\n",
    "        target='accent',\n",
    "        split_type='speaker_disjoint',\n",
    "        C=best_C,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    all_probe_results.append(result)\n",
    "    \n",
    "    decision = evaluate_probe_against_thresholds(\n",
    "        result, config['thresholds']['accent_probe']\n",
    "    )\n",
    "    print(f'  {source_name}: bal_acc={result.balanced_accuracy:.4f} '\n",
    "          f'CI=[{result.ci.ci_lower:.4f}, {result.ci.ci_upper:.4f}] '\n",
    "          f'delta={result.delta_pp:+.1f}pp C={best_C} ‚Üí {decision}')\n",
    "\n",
    "# Selectivity control for accent probes\n",
    "print('\\n=== SELECTIVITY CONTROL (accent probes) ===')\n",
    "accent_results = [r for r in all_probe_results if r.target == 'accent' and 'leakage' not in r.probe_name]\n",
    "for result in accent_results:\n",
    "    feat_dict = feature_sources[result.feature_source]\n",
    "    X_train, y_train = build_probe_data(feat_dict, train_entries, 'accent')\n",
    "    X_test, y_test = build_probe_data(feat_dict, test_entries, 'accent')\n",
    "    \n",
    "    sel = train_selectivity_control(\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        real_result=result,\n",
    "        seed=SEED,\n",
    "        C=result.regularization_C,\n",
    "    )\n",
    "    sel['probe_name'] = result.probe_name\n",
    "    sel['feature_source'] = result.feature_source\n",
    "    all_selectivity_results.append(sel)\n",
    "    \n",
    "    print(f'  {result.feature_source}: real={sel[\"real_bal_acc\"]:.4f} '\n",
    "          f'permuted={sel[\"permuted_bal_acc_mean\"]:.4f}¬±{sel[\"permuted_bal_acc_std\"]:.4f} '\n",
    "          f'selectivity={sel[\"selectivity_pp\"]:+.1f}pp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Leakage Probes\n",
    "print('\\n=== LEAKAGE PROBES ===')\n",
    "\n",
    "# --- Leakage A‚Üíspeaker: Do accent features contain speaker identity? ---\n",
    "# Uses STRATIFIED split (same speakers in train/test ‚Äî we need known speakers)\n",
    "print('Leakage A‚Üíspeaker (accent feature sources, stratified split):')\n",
    "\n",
    "strat_train_entries = stratified_entries['train']\n",
    "strat_test_entries = stratified_entries['test']\n",
    "\n",
    "# Accent feature sources: WavLM layers, backbone layers, acoustic\n",
    "# (NOT ECAPA ‚Äî those are speaker embeddings, not accent features)\n",
    "leakage_a2s_sources = {}\n",
    "for layer in SSL_LAYERS:\n",
    "    leakage_a2s_sources[f'wavlm_layer_{layer}'] = ssl_features[layer]\n",
    "for layer in BACKBONE_LAYERS:\n",
    "    if backbone_features[layer]:\n",
    "        leakage_a2s_sources[f'backbone_layer_{layer}'] = backbone_features[layer]\n",
    "leakage_a2s_sources['acoustic'] = acoustic_vectors\n",
    "\n",
    "leakage_a2s_results = []\n",
    "for source_name, feat_dict in leakage_a2s_sources.items():\n",
    "    X_train, y_train = build_probe_data(feat_dict, strat_train_entries, 'speaker_id')\n",
    "    X_test, y_test = build_probe_data(feat_dict, strat_test_entries, 'speaker_id')\n",
    "    \n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(f'  {source_name}: SKIPPED (no data)')\n",
    "        continue\n",
    "\n",
    "    result = train_linear_probe(\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        probe_name=f'leakage_a2s_{source_name}',\n",
    "        feature_source=source_name,\n",
    "        target='speaker_id',\n",
    "        split_type='stratified',\n",
    "        C=config['probes']['default_C'],\n",
    "        seed=SEED,\n",
    "    )\n",
    "    leakage_a2s_results.append(result)\n",
    "    all_probe_results.append(result)\n",
    "\n",
    "    leak_decision = evaluate_probe_against_thresholds(\n",
    "        result, config['thresholds']['leakage']\n",
    "    )\n",
    "    print(f'  {source_name}: bal_acc={result.balanced_accuracy:.4f} '\n",
    "          f'chance={result.chance_level:.4f} '\n",
    "          f'delta={result.delta_pp:+.1f}pp ‚Üí {leak_decision}')\n",
    "\n",
    "# Selectivity control for A‚Üíspeaker leakage\n",
    "print('\\n=== SELECTIVITY CONTROL (leakage A‚Üíspeaker) ===')\n",
    "for result in leakage_a2s_results:\n",
    "    feat_dict = leakage_a2s_sources[result.feature_source]\n",
    "    X_train, y_train = build_probe_data(feat_dict, strat_train_entries, 'speaker_id')\n",
    "    X_test, y_test = build_probe_data(feat_dict, strat_test_entries, 'speaker_id')\n",
    "\n",
    "    sel = train_selectivity_control(\n",
    "        X_train, y_train, X_test, y_test,\n",
    "        real_result=result,\n",
    "        seed=SEED,\n",
    "        C=result.regularization_C,\n",
    "    )\n",
    "    sel['probe_name'] = result.probe_name\n",
    "    sel['feature_source'] = result.feature_source\n",
    "    all_selectivity_results.append(sel)\n",
    "\n",
    "    print(f'  {result.feature_source}: real={sel[\"real_bal_acc\"]:.4f} '\n",
    "          f'permuted={sel[\"permuted_bal_acc_mean\"]:.4f}¬±{sel[\"permuted_bal_acc_std\"]:.4f} '\n",
    "          f'selectivity={sel[\"selectivity_pp\"]:+.1f}pp')\n",
    "\n",
    "# --- Leakage S‚Üíaccent: Do speaker features contain accent info? ---\n",
    "# Uses SPEAKER-DISJOINT split (different speakers in test ‚Äî tests generalization)\n",
    "print('\\nLeakage S‚Üíaccent (ECAPA embeddings, speaker-disjoint split):')\n",
    "X_train, y_train = build_probe_data(ecapa_embeddings, train_entries, 'accent')\n",
    "X_test, y_test = build_probe_data(ecapa_embeddings, test_entries, 'accent')\n",
    "\n",
    "leakage_s2a = train_linear_probe(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    probe_name='leakage_s2a_ecapa',\n",
    "    feature_source='ecapa',\n",
    "    target='accent',\n",
    "    split_type='speaker_disjoint',\n",
    "    C=config['probes']['default_C'],\n",
    "    seed=SEED,\n",
    ")\n",
    "all_probe_results.append(leakage_s2a)\n",
    "\n",
    "leak_decision = evaluate_probe_against_thresholds(\n",
    "    leakage_s2a, config['thresholds']['leakage']\n",
    ")\n",
    "print(f'  bal_acc={leakage_s2a.balanced_accuracy:.4f} '\n",
    "      f'chance={leakage_s2a.chance_level:.4f} '\n",
    "      f'delta={leakage_s2a.delta_pp:+.1f}pp ‚Üí {leak_decision}')\n",
    "\n",
    "# Selectivity control for S‚Üíaccent leakage\n",
    "sel_s2a = train_selectivity_control(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    real_result=leakage_s2a,\n",
    "    seed=SEED,\n",
    "    C=leakage_s2a.regularization_C,\n",
    ")\n",
    "sel_s2a['probe_name'] = leakage_s2a.probe_name\n",
    "sel_s2a['feature_source'] = leakage_s2a.feature_source\n",
    "all_selectivity_results.append(sel_s2a)\n",
    "print(f'  selectivity: real={sel_s2a[\"real_bal_acc\"]:.4f} '\n",
    "      f'permuted={sel_s2a[\"permuted_bal_acc_mean\"]:.4f}¬±{sel_s2a[\"permuted_bal_acc_std\"]:.4f} '\n",
    "      f'selectivity={sel_s2a[\"selectivity_pp\"]:+.1f}pp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Confusion Matrices (best accent probe)\n",
    "accent_results = [r for r in all_probe_results if r.target == 'accent' and 'leakage' not in r.probe_name]\n",
    "if accent_results:\n",
    "    best = max(accent_results, key=lambda r: r.balanced_accuracy)\n",
    "    print(f'Best accent probe: {best.feature_source} (bal_acc={best.balanced_accuracy:.4f})')\n",
    "    \n",
    "    if best.confusion_matrix is not None:\n",
    "        Path('reports/figures').mkdir(parents=True, exist_ok=True)\n",
    "        plot_confusion_matrix(\n",
    "            best.confusion_matrix,\n",
    "            best.confusion_labels,\n",
    "            title=f'Accent Confusion Matrix ({best.feature_source})',\n",
    "            output_path=Path('reports/figures/confusion_matrix_accent.png'),\n",
    "        )\n",
    "        print('Confusion matrix saved to reports/figures/confusion_matrix_accent.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Robustness (Multiple Seeds)\n",
    "\n",
    "Repete o melhor probe com 3 seeds para reportar m√©dia e desvio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBUSTNESS_SEEDS = config['seed']['robustness_seeds']\n",
    "print(f'=== ROBUSTNESS CHECK (seeds: {ROBUSTNESS_SEEDS}) ===')\n",
    "\n",
    "if accent_results:\n",
    "    best_source = best.feature_source\n",
    "    best_features = feature_sources[best_source]\n",
    "    \n",
    "    seed_results = []\n",
    "    for s in ROBUSTNESS_SEEDS:\n",
    "        set_global_seed(s)\n",
    "        X_tr, y_tr = build_probe_data(best_features, train_entries, 'accent')\n",
    "        X_te, y_te = build_probe_data(best_features, test_entries, 'accent')\n",
    "        \n",
    "        r = train_linear_probe(\n",
    "            X_tr, y_tr, X_te, y_te,\n",
    "            probe_name=f'accent_{best_source}_seed{s}',\n",
    "            feature_source=best_source,\n",
    "            target='accent',\n",
    "            split_type='speaker_disjoint',\n",
    "            seed=s,\n",
    "            compute_ci=True,\n",
    "        )\n",
    "        seed_results.append(r)\n",
    "        print(f'  Seed {s}: bal_acc={r.balanced_accuracy:.4f} CI=[{r.ci.ci_lower:.4f}, {r.ci.ci_upper:.4f}]')\n",
    "    \n",
    "    accs = [r.balanced_accuracy for r in seed_results]\n",
    "    print(f'\\n  Mean: {np.mean(accs):.4f} ¬± {np.std(accs):.4f}')\n",
    "    \n",
    "    # Restore original seed\n",
    "    set_global_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Gate Decision\n",
    "\n",
    "Avalia√ß√£o autom√°tica contra os thresholds do protocolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('STAGE 1.5 ‚Äî GATE DECISION')\n",
    "print('=' * 60)\n",
    "\n",
    "all_decisions = []\n",
    "\n",
    "# Check confound blocking first ‚Äî if any confound is blocking, gate is FAIL\n",
    "blocking_confounds = [r for r in confound_results if r.is_blocking]\n",
    "if blocking_confounds:\n",
    "    print('\\nCONFOUND BLOCKING:')\n",
    "    for bc in blocking_confounds:\n",
    "        print(f'  {bc.variable_a} x {bc.variable_b}: '\n",
    "              f'{bc.effect_size_name}={bc.effect_size:.4f}')\n",
    "        print(f'  Interpretation: {bc.interpretation}')\n",
    "    all_decisions.append('FAIL')\n",
    "    print('  Decision: FAIL (confound blocking)')\n",
    "else:\n",
    "    print('\\nConfound check: PASS (no blocking confounds)')\n",
    "\n",
    "# Best accent probe\n",
    "accent_results = [r for r in all_probe_results if r.target == 'accent' and 'leakage' not in r.probe_name]\n",
    "if accent_results:\n",
    "    best = max(accent_results, key=lambda r: r.balanced_accuracy)\n",
    "    accent_decision = evaluate_probe_against_thresholds(\n",
    "        best, config['thresholds']['accent_probe']\n",
    "    )\n",
    "    all_decisions.append(accent_decision)\n",
    "    print(f'\\nAccent probe ({best.feature_source}):')\n",
    "    print(f'  bal_acc = {best.balanced_accuracy:.4f}')\n",
    "    print(f'  CI 95% = [{best.ci.ci_lower:.4f}, {best.ci.ci_upper:.4f}]')\n",
    "    print(f'  Chance = {best.chance_level:.4f}')\n",
    "    print(f'  C = {best.regularization_C}')\n",
    "    print(f'  Decision: {accent_decision}')\n",
    "\n",
    "# Leakage\n",
    "leakage_results = [r for r in all_probe_results if 'leakage' in r.probe_name]\n",
    "for lr in leakage_results:\n",
    "    ld = evaluate_probe_against_thresholds(lr, config['thresholds']['leakage'])\n",
    "    all_decisions.append(ld)\n",
    "    print(f'\\nLeakage {lr.probe_name}:')\n",
    "    print(f'  bal_acc = {lr.balanced_accuracy:.4f}')\n",
    "    print(f'  Chance = {lr.chance_level:.4f}')\n",
    "    print(f'  Delta = {lr.delta_pp:+.1f}pp')\n",
    "    print(f'  Decision: {ld}')\n",
    "\n",
    "# Overall\n",
    "print(f'\\n{\"=\" * 60}')\n",
    "if 'FAIL' in all_decisions:\n",
    "    overall = 'FAIL'\n",
    "elif 'GO_CONDITIONAL' in all_decisions:\n",
    "    overall = 'GO_CONDITIONAL'\n",
    "elif len(all_decisions) == 0:\n",
    "    overall = 'NOT_EVALUATED'\n",
    "else:\n",
    "    overall = 'GO'\n",
    "print(f'OVERALL GATE DECISION: {overall}')\n",
    "print(f'{\"=\" * 60}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Report\n",
    "\n",
    "Gera `stage1_5_report.json` com todos os resultados para auditoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "# Get git commit hash\n",
    "try:\n",
    "    commit_hash = subprocess.check_output(\n",
    "        ['git', 'rev-parse', 'HEAD'], text=True\n",
    "    ).strip()\n",
    "except Exception:\n",
    "    commit_hash = 'unknown'\n",
    "\n",
    "report = {\n",
    "    'experiment': config['experiment']['name'],\n",
    "    'date': datetime.now().isoformat(),\n",
    "    'commit_hash': commit_hash,\n",
    "    'seed': SEED,\n",
    "    'environment': {\n",
    "        'cuda_version': torch.version.cuda if torch.cuda.is_available() else None,\n",
    "        'cudnn_version': torch.backends.cudnn.version() if torch.cuda.is_available() else None,\n",
    "        'torch_version': torch.__version__,\n",
    "        'commit_hash': config.get('experiment', {}).get('commit_hash'),\n",
    "    },\n",
    "    'dataset': {\n",
    "        'name': config['dataset']['name'],\n",
    "        'manifest_sha256': build_stats.get('manifest_sha256'),\n",
    "        'total_entries': len(entries),\n",
    "        'regions': build_stats.get('regions'),\n",
    "    },\n",
    "    'splits': split_info.to_dict(),\n",
    "    'stratified_splits': stratified_split_info.to_dict(),\n",
    "    'confounds': [\n",
    "        {\n",
    "            'test': r.test_name,\n",
    "            'variables': f'{r.variable_a} x {r.variable_b}',\n",
    "            'statistic': r.statistic,\n",
    "            'p_value': r.p_value,\n",
    "            'effect_size': r.effect_size,\n",
    "            'is_blocking': r.is_blocking,\n",
    "            'interpretation': r.interpretation,\n",
    "        }\n",
    "        for r in confound_results\n",
    "    ],\n",
    "    'speaker_similarity_baseline': {\n",
    "        'intra': {\n",
    "            'mean': sim_baseline['intra']['mean'],\n",
    "            'std': sim_baseline['intra']['std'],\n",
    "            'ci_lower': intra_ci.ci_lower,\n",
    "            'ci_upper': intra_ci.ci_upper,\n",
    "            'n_pairs': sim_baseline['intra']['n_pairs'],\n",
    "        },\n",
    "        'inter': {\n",
    "            'mean': sim_baseline['inter']['mean'],\n",
    "            'std': sim_baseline['inter']['std'],\n",
    "            'ci_lower': inter_ci.ci_lower,\n",
    "            'ci_upper': inter_ci.ci_upper,\n",
    "            'n_pairs': sim_baseline['inter']['n_pairs'],\n",
    "        },\n",
    "    },\n",
    "    'probes': [\n",
    "        {\n",
    "            'name': r.probe_name,\n",
    "            'feature_source': r.feature_source,\n",
    "            'target': r.target,\n",
    "            'split_type': r.split_type,\n",
    "            'balanced_accuracy': r.balanced_accuracy,\n",
    "            'f1_macro': r.f1_macro,\n",
    "            'chance_level': r.chance_level,\n",
    "            'delta_pp': r.delta_pp,\n",
    "            'ci_lower': r.ci.ci_lower if r.ci else None,\n",
    "            'ci_upper': r.ci.ci_upper if r.ci else None,\n",
    "            'n_train': r.n_train,\n",
    "            'n_test': r.n_test,\n",
    "            'n_classes': r.n_classes,\n",
    "            'C': r.regularization_C,\n",
    "        }\n",
    "        for r in all_probe_results\n",
    "    ],\n",
    "    'selectivity_controls': all_selectivity_results,\n",
    "    'gate_decision': overall if 'overall' in dir() else 'NOT_EVALUATED',\n",
    "}\n",
    "\n",
    "Path('reports').mkdir(exist_ok=True)\n",
    "report_path = Path('reports/stage1_5_report.json')\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=2, default=str)\n",
    "\n",
    "print(f'Report saved to {report_path}')\n",
    "print(f'Total probe results: {len(all_probe_results)}')\n",
    "print(f'Total selectivity controls: {len(all_selectivity_results)}')\n",
    "print(f'Gate decision: {report[\"gate_decision\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
